{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlemke/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/nlemke/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import configs, torch\n",
    "from src.models.Model_OctreeNCA_2d_patching2 import OctreeNCA2DPatch2\n",
    "import time, json, einops\n",
    "import torch.nn.functional as F\n",
    "import math, numpy as np\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "study_config = {\n",
    "    'experiment.name': r'pesoS10NN',\n",
    "    'experiment.description': \"OctreeNCA2DSegmentation\",\n",
    "\n",
    "    'model.output_channels': 1,\n",
    "}\n",
    "study_config = study_config | configs.models.peso_med.peso_model_config\n",
    "study_config = study_config | configs.trainers.nca.nca_trainer_config\n",
    "study_config = study_config | configs.datasets.peso.peso_dataset_config\n",
    "study_config = study_config | configs.tasks.segmentation.segmentation_task_config\n",
    "study_config = study_config | configs.default.default_config\n",
    "\n",
    "study_config['experiment.logging.also_eval_on_train'] = False\n",
    "study_config['experiment.logging.evaluate_interval'] = study_config['trainer.n_epochs']+1\n",
    "study_config['experiment.task.score'] = [\"src.scores.PatchwiseDiceScore.PatchwiseDiceScore\",\n",
    "                                         \"src.scores.PatchwiseIoUScore.PatchwiseIoUScore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_config['experiment.device'] = \"cpu\"\n",
    "assert study_config['model.backbone_class'] == \"BasicNCA2DFast\"\n",
    "model = OctreeNCA2DPatch2(study_config).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_resolutions(x_shape, model):\n",
    "    upscale_factors = []\n",
    "    for i in range(len(model.octree_res)-1):\n",
    "        t = []\n",
    "        for c in range(2):\n",
    "            t.append(model.octree_res[i][c]//model.octree_res[i+1][c])\n",
    "        upscale_factors.append(t)\n",
    "\n",
    "    new_octree_res = [tuple(x_shape)]\n",
    "    for i in range(1, len(model.octree_res)):\n",
    "        downsample_factor = np.array(model.octree_res[i-1]) / np.array(model.octree_res[i])\n",
    "        new_octree_res.append([math.ceil(new_octree_res[i-1][0] / downsample_factor[0]), \n",
    "                                math.ceil(new_octree_res[i-1][1] / downsample_factor[1])])\n",
    "    return new_octree_res\n",
    "\n",
    "def remove_names(x: torch.Tensor):\n",
    "    x.names = [None] * len(x.names)\n",
    "    return x\n",
    "\n",
    "def align_tensor_to(x: torch.Tensor, target: str):\n",
    "    if isinstance(target, tuple):\n",
    "        target_str = ' '.join(target)\n",
    "    elif isinstance(target, str): \n",
    "        if max(map(len, target.split())) != 1:\n",
    "            #targets are like \"BCHW\"\n",
    "            target_str = ' '.join(target)\n",
    "        else:\n",
    "            #targets are like \"B C H W\"\n",
    "            target_str = target\n",
    "            target = target.replace(\" \", \"\")\n",
    "\n",
    "\n",
    "    pattern = f\"{' '.join(x.names)} -> {target_str}\"\n",
    "    x = remove_names(x)\n",
    "    x = einops.rearrange(x, pattern)\n",
    "    x.names = tuple(target)\n",
    "    return x\n",
    "\n",
    "def downscale(x: torch.Tensor, out_size):\n",
    "    x = align_tensor_to(x, \"BCHW\")\n",
    "    remove_names(x)\n",
    "\n",
    "    out = F.interpolate(x, size=out_size)\n",
    "    out.names = ('B', 'C', 'H', 'W')\n",
    "    x.names = ('B', 'C', 'H', 'W')\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def perform_inference(slide, computed_resolutions):\n",
    "    seed = torch.zeros(1, *computed_resolutions[-1], model.channel_n,\n",
    "                                    dtype=torch.float, device=slide.device,\n",
    "                                    names=('B', 'H', 'W', 'C'))\n",
    "    temp = downscale(slide, computed_resolutions[-1])\n",
    "    temp = align_tensor_to(temp, \"BHWC\")\n",
    "    remove_names(temp)\n",
    "    remove_names(seed)\n",
    "    slide = align_tensor_to(slide, \"BHWC\")\n",
    "    remove_names(slide)\n",
    "    seed[:,:,:,:model.input_channels] = temp\n",
    "\n",
    "    state = model.backbone_ncas[1](seed, steps=model.inference_steps[1], fire_rate=model.fire_rate)\n",
    "\n",
    "\n",
    "    state = einops.rearrange(state, \"B H W C -> B C H W\")\n",
    "    state = torch.nn.Upsample(size=computed_resolutions[0], mode='nearest')(state)\n",
    "    temp = F.interpolate(einops.rearrange(slide, \"B H W C -> B C H W\"), size=computed_resolutions[0])\n",
    "    state[0,:model.input_channels,:,:] = temp[0]\n",
    "    state = einops.rearrange(state, \"B C H W -> B H W C\")\n",
    "    state = model.backbone_ncas[0](state, steps=model.inference_steps[0], fire_rate=model.fire_rate)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_inference_and_measure_time(img_dim):\n",
    "    input_img = torch.rand(1, 3, img_dim, img_dim, names=('B', 'C', 'H', 'W'))  #this must be BCHW\n",
    "    computed_resolutions = compute_resolutions(input_img.shape[2:], model)\n",
    "    start = time.time()\n",
    "    out = perform_inference(input_img, computed_resolutions)\n",
    "    end = time.time()\n",
    "    assert out.shape[1:3] == (img_dim, img_dim)\n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "run 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1571296/2040333383.py:2: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1921.)\n",
      "  input_img = torch.rand(1, 3, img_dim, img_dim, names=('B', 'C', 'H', 'W'))  #this must be BCHW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "run 2\n",
      "640\n",
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "960\n",
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "1280\n",
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "1600\n",
      "run 0\n",
      "run 1\n",
      "run 2\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for img_dim in [320, 320*2, 320*3, 320*4, 320*5]:\n",
    "    print(img_dim)\n",
    "    timings = []\n",
    "    for i in range(3):\n",
    "        print(\"run\", i)\n",
    "        timings.append(perform_inference_and_measure_time(img_dim))\n",
    "\n",
    "    results[img_dim] = timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"john_timing_results_med_pi.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
