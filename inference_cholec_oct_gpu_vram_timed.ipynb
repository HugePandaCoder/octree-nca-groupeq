{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlemke/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/nlemke/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7e0c969c3370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio, json, os, torch, einops, math, tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from src.datasets.Dataset_CholecSeg_preprocessed import Dataset_CholecSeg_preprocessed\n",
    "from src.utils.BaselineConfigs import EXP_OctreeNCA3D\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration is missing keys: '['experiment.run_hash']'. Check if you are loading the correct experiment.\n",
      "Timeout Error:  The file lock '/local/scratch/clmn1/octree_study_new/Aim/.aim/locks/a389bc1d54004f328d017483.softlock' could not be acquired.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Force-releasing locks for Run 'a389bc1d54004f328d017483'. Data corruption may occur if there is active process writing to Run 'a389bc1d54004f328d017483'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload State 2000\n",
      "\n",
      "-------- Experiment Setup --------\n",
      "{\n",
      "    \"experiment.name\": \"cholecfFixAbl_none_10_1.0_16_1_1.0_0.99\",\n",
      "    \"experiment.description\": \"OctreeNCASegmentation\",\n",
      "    \"model.output_channels\": 5,\n",
      "    \"model.channel_n\": 16,\n",
      "    \"model.fire_rate\": 0.5,\n",
      "    \"model.kernel_size\": [\n",
      "        3,\n",
      "        3,\n",
      "        3,\n",
      "        3,\n",
      "        3\n",
      "    ],\n",
      "    \"model.hidden_size\": 64,\n",
      "    \"model.batchnorm_track_running_stats\": false,\n",
      "    \"model.train.patch_sizes\": [\n",
      "        [\n",
      "            60,\n",
      "            106,\n",
      "            20\n",
      "        ],\n",
      "        [\n",
      "            60,\n",
      "            106,\n",
      "            20\n",
      "        ],\n",
      "        null,\n",
      "        null,\n",
      "        null\n",
      "    ],\n",
      "    \"model.train.loss_weighted_patching\": false,\n",
      "    \"model.eval.patch_wise\": false,\n",
      "    \"model.octree.res_and_steps\": [\n",
      "        [\n",
      "            [\n",
      "                240,\n",
      "                432,\n",
      "                80\n",
      "            ],\n",
      "            10\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                120,\n",
      "                216,\n",
      "                40\n",
      "            ],\n",
      "            10\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                60,\n",
      "                108,\n",
      "                20\n",
      "            ],\n",
      "            10\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                30,\n",
      "                54,\n",
      "                10\n",
      "            ],\n",
      "            10\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                15,\n",
      "                27,\n",
      "                5\n",
      "            ],\n",
      "            27\n",
      "        ]\n",
      "    ],\n",
      "    \"model.octree.separate_models\": true,\n",
      "    \"model.backbone_class\": \"BasicNCA3DFast\",\n",
      "    \"model.vitca\": false,\n",
      "    \"model.vitca.depth\": 1,\n",
      "    \"model.vitca.heads\": 4,\n",
      "    \"model.vitca.mlp_dim\": 64,\n",
      "    \"model.vitca.dropout\": 0.0,\n",
      "    \"model.vitca.positional_embedding\": \"vit_handcrafted\",\n",
      "    \"model.vitca.embed_cells\": true,\n",
      "    \"model.vitca.embed_dim\": 128,\n",
      "    \"model.vitca.embed_dropout\": 0.0,\n",
      "    \"trainer.optimizer\": \"torch.optim.Adam\",\n",
      "    \"trainer.optimizer.lr\": 0.0016,\n",
      "    \"trainer.optimizer.betas\": [\n",
      "        0.9,\n",
      "        0.99\n",
      "    ],\n",
      "    \"trainer.lr_scheduler\": \"torch.optim.lr_scheduler.ExponentialLR\",\n",
      "    \"trainer.lr_scheduler.gamma\": 0.9992002799440071,\n",
      "    \"trainer.update_lr_per_epoch\": true,\n",
      "    \"trainer.normalize_gradients\": null,\n",
      "    \"trainer.n_epochs\": 2000,\n",
      "    \"trainer.find_best_model_on\": null,\n",
      "    \"trainer.always_eval_in_last_epochs\": null,\n",
      "    \"trainer.ema\": true,\n",
      "    \"trainer.ema.decay\": 0.99,\n",
      "    \"trainer.ema.update_per\": \"epoch\",\n",
      "    \"experiment.dataset.img_path\": \"clmn1/data/cholecseg8k_preprocessed_2/\",\n",
      "    \"experiment.dataset.label_path\": \"clmn1/data/cholecseg8k_preprocessed_2/\",\n",
      "    \"experiment.dataset.keep_original_scale\": true,\n",
      "    \"experiment.dataset.rescale\": true,\n",
      "    \"experiment.dataset.input_size\": [\n",
      "        240,\n",
      "        432,\n",
      "        80\n",
      "    ],\n",
      "    \"experiment.dataset.split_file\": \"clmn1/octree_study/cholec_split.pkl\",\n",
      "    \"model.input_channels\": 3,\n",
      "    \"trainer.num_steps_per_epoch\": null,\n",
      "    \"trainer.batch_size\": 1,\n",
      "    \"trainer.batch_duplication\": 1,\n",
      "    \"experiment.task\": \"segmentation\",\n",
      "    \"experiment.task.score\": [\n",
      "        \"src.scores.DiceScore.DiceScore\",\n",
      "        \"src.scores.IoUScore.IoUScore\"\n",
      "    ],\n",
      "    \"trainer.losses\": [\n",
      "        \"src.losses.DiceLoss.DiceLoss\",\n",
      "        \"src.losses.BCELoss.BCELoss\"\n",
      "    ],\n",
      "    \"trainer.losses.parameters\": [\n",
      "        {},\n",
      "        {}\n",
      "    ],\n",
      "    \"trainer.loss_weights\": [\n",
      "        1.0,\n",
      "        1.0\n",
      "    ],\n",
      "    \"experiment.data_split\": [\n",
      "        0.7,\n",
      "        0,\n",
      "        0.3\n",
      "    ],\n",
      "    \"experiment.save_interval\": 50,\n",
      "    \"experiment.device\": \"cuda:0\",\n",
      "    \"experiment.logging.also_eval_on_train\": false,\n",
      "    \"experiment.logging.track_gradient_norm\": true,\n",
      "    \"experiment.logging.evaluate_interval\": 50,\n",
      "    \"performance.compile\": false,\n",
      "    \"performance.data_parallel\": false,\n",
      "    \"performance.num_workers\": 8,\n",
      "    \"performance.unlock_CPU\": true,\n",
      "    \"performance.inplace_operations\": true,\n",
      "    \"trainer.datagen.batchgenerators\": true,\n",
      "    \"trainer.datagen.augmentations\": true,\n",
      "    \"trainer.datagen.difficulty_weighted_sampling\": false,\n",
      "    \"trainer.gradient_accumulation\": false,\n",
      "    \"trainer.train_quality_control\": false,\n",
      "    \"model.normalization\": \"none\",\n",
      "    \"experiment.model_path\": \"clmn1/octree_study_new/Experiments/cholecfFixAbl_none_10_1.0_16_1_1.0_0.99_OctreeNCASegmentation\",\n",
      "    \"experiment.git_hash\": \"0cc72993c85b2255f975996acacda676e8519749\",\n",
      "    \"experiment.run_hash\": \"a389bc1d54004f328d017483\"\n",
      "}\n",
      "-------- Experiment Setup --------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OctreeNCA3DPatch2(\n",
       "  (backbone_ncas): ModuleList(\n",
       "    (0-4): 5 x BasicNCA3DFast(\n",
       "      (fc0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (fc1): Conv3d(64, 13, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=16, padding_mode=reflect)\n",
       "      (bn): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.Model_OctreeNCA_3d_patching2 import OctreeNCA3DPatch2\n",
    "\n",
    "\n",
    "model_path = \"/local/scratch/clmn1/octree_study_new/Experiments/cholecfFixAbl_none_10_1.0_16_1_1.0_0.99_OctreeNCASegmentation/\"\n",
    "with open(os.path.join(model_path, \"config.json\")) as f:\n",
    "    config = json.load(f) \n",
    "\n",
    "exp = EXP_OctreeNCA3D().createExperiment(config, detail_config={}, \n",
    "                                        dataset_class=Dataset_CholecSeg_preprocessed, dataset_args = {\n",
    "                                        })\n",
    "\n",
    "model: OctreeNCA3DPatch2 = exp.model\n",
    "assert isinstance(model, OctreeNCA3DPatch2)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale(x: torch.Tensor, out_size):\n",
    "    x = model.align_tensor_to(x, \"BCHWD\")\n",
    "    model.remove_names(x)\n",
    "\n",
    "    out = F.interpolate(x, size=out_size)\n",
    "    out.names = ('B', 'C', 'H', 'W', 'D')\n",
    "    x.names = ('B', 'C', 'H', 'W', 'D')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 240, 424, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = \"/local/scratch/Cholec80/cholec80_full_set/videos/video01.mp4\"\n",
    "video_reader = imageio.get_reader(video_path)\n",
    "n_frames = video_reader.get_meta_data()['duration'] * video_reader.get_meta_data()['fps']\n",
    "\n",
    "num_seconds = 6\n",
    "\n",
    "video = []\n",
    "for frame in range(int(video_reader.get_meta_data()['fps'] * num_seconds)):\n",
    "    image = video_reader.get_data(frame)\n",
    "    video.append(image[None, ...])\n",
    "\n",
    "video = np.concatenate(video, axis=0)\n",
    "video = einops.rearrange(video, 't h w c ->  h w (t c)')\n",
    "\n",
    "\n",
    "outstacks = []\n",
    "for i in range(math.ceil(video.shape[-1] / 500)):\n",
    "    outstack = cv2.resize(video[..., i*500:(i+1)*500], (424, 240))\n",
    "    outstacks.append(outstack)\n",
    "video = np.concatenate(outstacks, axis=-1)\n",
    "video = einops.rearrange(video, 'h w (t c) -> t h w c', c=3).astype(np.float32)\n",
    "video /= 255.0\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "video -= mean\n",
    "video /= std\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[240, 424, 150], [120, 212, 75], [60, 106, 38], [30, 53, 19], [15, 27, 10]]\n"
     ]
    }
   ],
   "source": [
    "video_tensor = torch.from_numpy(einops.rearrange(video, 'D H W C -> 1 H W D C'))\n",
    "video_tensor.names = ('B', 'H', 'W', 'D', 'C')\n",
    "computed_resolutions = model.compute_octree_res(video_tensor)\n",
    "print(computed_resolutions)\n",
    "\n",
    "seed = torch.zeros(1, *computed_resolutions[-1], model.channel_n,\n",
    "                                dtype=torch.float, device=model.device, \n",
    "                                names=('B', 'H', 'W', 'D', 'C'))\n",
    "temp = downscale(video_tensor, computed_resolutions[-1])\n",
    "temp = model.align_tensor_to(temp, \"BHWDC\")\n",
    "model.remove_names(temp)\n",
    "model.remove_names(seed)\n",
    "seed[:,:,:,:,:model.input_channels] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 958.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 830.69 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Of the allocated memory 20.72 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m state[\u001b[38;5;241m0\u001b[39m,:model\u001b[38;5;241m.\u001b[39minput_channels,:,:,:] \u001b[38;5;241m=\u001b[39m temp[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m state \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 C H W D -> 1 H W D C\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone_ncas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfire_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfire_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m-\u001b[39mstart)\n",
      "File \u001b[0;32m~/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/gris/gris-f/homestud/nlemke/NCA/src/models/Model_BasicNCA3D_fast.py:115\u001b[0m, in \u001b[0;36mBasicNCA3DFast.forward\u001b[0;34m(self, x, steps, fire_rate)\u001b[0m\n\u001b[1;32m    112\u001b[0m const_inputs \u001b[38;5;241m=\u001b[39m state[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m--> 115\u001b[0m     new_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfire_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([const_inputs, new_state], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m einops\u001b[38;5;241m.\u001b[39mrearrange(state, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb c h w d -> b h w d c\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/gris/gris-f/homestud/nlemke/NCA/src/models/Model_BasicNCA3D_fast.py:65\u001b[0m, in \u001b[0;36mBasicNCA3DFast.update\u001b[0;34m(self, state, fire_rate)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, fire_rate):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# state.shape: BCHWD\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     delta_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     delta_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([state, delta_state], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m     delta_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc0(delta_state)\n",
      "File \u001b[0;32m~/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/torch/nn/modules/conv.py:710\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_conv_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, weight: Tensor, bias: Optional[Tensor]):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m--> 710\u001b[0m             \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reversed_padding_repeated_twice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_mode\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    713\u001b[0m             weight,\n\u001b[1;32m    714\u001b[0m             bias,\n\u001b[1;32m    715\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    716\u001b[0m             _triple(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    717\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation,\n\u001b[1;32m    718\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m         )\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    722\u001b[0m     )\n",
      "File \u001b[0;32m~/remote/miniconda3/envs/nca3/lib/python3.10/site-packages/torch/nn/functional.py:5096\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   5089\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   5090\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[1;32m   5091\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   5092\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   5093\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[1;32m   5094\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5095\u001b[0m             )\u001b[38;5;241m.\u001b[39m_replication_pad(\u001b[38;5;28minput\u001b[39m, pad)\n\u001b[0;32m-> 5096\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 958.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 830.69 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Of the allocated memory 20.72 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "start = time.time()\n",
    "state = model.backbone_ncas[4](seed, steps=model.inference_steps[4], fire_rate=model.fire_rate)\n",
    "\n",
    "state = einops.rearrange(state, '1 H W D C -> 1 C H W D')\n",
    "state = torch.nn.Upsample(size=computed_resolutions[3], mode='nearest')(state)\n",
    "temp = F.interpolate(einops.rearrange(video_tensor, \"1 h w t c -> 1 c h w t\"), size=computed_resolutions[3])\n",
    "state[0,:model.input_channels,:,:,:] = temp[0]\n",
    "state = einops.rearrange(state, '1 C H W D -> 1 H W D C')\n",
    "state = model.backbone_ncas[3](state, steps=model.inference_steps[3], fire_rate=model.fire_rate)\n",
    "\n",
    "state = einops.rearrange(state, '1 H W D C -> 1 C H W D')\n",
    "state = torch.nn.Upsample(size=computed_resolutions[2], mode='nearest')(state)\n",
    "temp = F.interpolate(einops.rearrange(video_tensor, \"1 h w t c -> 1 c h w t\"), size=computed_resolutions[2])\n",
    "state[0,:model.input_channels,:,:,:] = temp[0]\n",
    "state = einops.rearrange(state, '1 C H W D -> 1 H W D C')\n",
    "state = model.backbone_ncas[2](state, steps=model.inference_steps[2], fire_rate=model.fire_rate)\n",
    "\n",
    "state = einops.rearrange(state, '1 H W D C -> 1 C H W D')\n",
    "state = torch.nn.Upsample(size=computed_resolutions[1], mode='nearest')(state)\n",
    "temp = F.interpolate(einops.rearrange(video_tensor, \"1 h w t c -> 1 c h w t\"), size=computed_resolutions[1])\n",
    "state[0,:model.input_channels,:,:,:] = temp[0]\n",
    "state = einops.rearrange(state, '1 C H W D -> 1 H W D C')\n",
    "state = model.backbone_ncas[1](state, steps=model.inference_steps[1], fire_rate=model.fire_rate)\n",
    "\n",
    "state = einops.rearrange(state, '1 H W D C -> 1 C H W D')\n",
    "state = torch.nn.Upsample(size=computed_resolutions[0], mode='nearest')(state)\n",
    "temp = F.interpolate(einops.rearrange(video_tensor, \"1 h w t c -> 1 c h w t\"), size=computed_resolutions[0])\n",
    "state[0,:model.input_channels,:,:,:] = temp[0]\n",
    "state = einops.rearrange(state, '1 C H W D -> 1 H W D C')\n",
    "state = model.backbone_ncas[0](state, steps=model.inference_steps[0], fire_rate=model.fire_rate)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: \", end-start)\n",
    "print(torch.cuda.max_memory_allocated() / 1000**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
